{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mac install:\n",
    "step 1 install docker toolbox:\n",
    "https://docs.docker.com/mac/step_one/\n",
    "\n",
    "step 2 launch Docker Quickstart Terminal\n",
    "\n",
    "step 3: to test docker installation type in the Docker terminal:\n",
    "docker run hello-world\n",
    "\n",
    "step 4: test of the installation of rnn software:\n",
    "    step 4_1:\n",
    "    create a folder to store the result on your computer ex:\n",
    "\n",
    "    ex /mypersonalfiles/result\n",
    "    \n",
    "    step 4_2:\n",
    "    run on Docker terminal: \n",
    "    docker run  -v /mypersonalfiles/result:/src/results -e=\"THEANO_FLAGS='device=cpu'\" jeammimi/docker-keras-rnn  python main.py 2 Tracking_results-inspected__MinFrames_30.mat\n",
    "\n",
    "\n",
    "    (where you replace  /mypersonalfiles/result by the folder that you created on step 4_1):\n",
    "    \n",
    "    (it may take a while to download the docker image (1 Gb))\n",
    "    \n",
    "    step 4_3:\n",
    "    \n",
    "    check your folder /mypersonalfiles/result there shourd be some result files\n",
    "    \n",
    "\n",
    "step 5 running it on your on experiment:\n",
    "\n",
    "    docker run  -v /mypersonalfiles/mytraj.mat:/src/test.mat -v /mypersonalfiles/result:/src/results -e=\"THEANO_FLAGS='device=cpu'\" jeammimi/docker-keras-rnn  python main.py 2 test.mat\n",
    "\n",
    "    (where you replace  /mypersonalfiles/result by the folder that you created on your computer ,\n",
    "    and where you replace  /mypersonalfiles/mytraj.mat by the files which contain your trajectories)\n",
    "    \n",
    "    \n",
    "SPECIFIC issues:\n",
    "    mac  the file and the directory must be in /Users and not in /Volumes otherwise\n",
    "         there would be an error: test.mat is a directory.\n",
    "         error: test.mat is a directory can also happend if there is a mistake in the path of the file.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: __main__.py [-h] [--res RES] [--sub SUB] [--batch BATCH] ndim trackfile\n",
      "__main__.py: error: argument ndim: invalid int value: '/home/jarbona/.ipython/profile_nbserver/security/kernel-a8e57715-ffb0-46f6-b017-bc52076d3218.json'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To exit: use 'exit', 'quit', or Ctrl-D.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "sudo docker daemon\n",
    "docker run -ti --dns=157.99.64.65 --name running jeammimi/docker-keras-rnn:v5 /bin/sh\n",
    "#rm src in docker\n",
    "docker cp src running:/src           #to copy file from here to container\n",
    "docker commit -m \"My modif\" running jeammimi/docker-keras-rnn:v2   #to save running container\n",
    "\n",
    "docker stop $(docker ps -a -q)\n",
    "docker rm $(docker ps -a -q)\n",
    "\n",
    "docker run  -v /home/jarbona/docker-app/src/Tracking_results-inspected__MinFrames_30.mat:/src/test.mat -v /home/jarbona/restult_tmp/:/src/results -e=\"THEANO_FLAGS='device=cpu'\" docker-keras4  python main.py 2 test.mat\n",
    "\n",
    "run   -v /home/jarbona/docker-app/test/:/src/results -e=\"THEANO_FLAGS='device=cpu'\" jeammimi/docker-keras-rnn:v9  python main.py 2 results --batch 1\n",
    "\n",
    "docker push jeammimi/docker-keras-rnn:v2\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import argparse\n",
    "\n",
    "#theano.config.device=\"cpu\"\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"ndim\", help=\"number of dimension\",\n",
    "                    type=int)\n",
    "parser.add_argument(\"trackfile\", help=\"trackfile or directory (if batch mode)\")\n",
    "\n",
    "parser.add_argument(\"--res\", help=\"result folder\",default=\"results/\")\n",
    "\n",
    "parser.add_argument(\"--sub\", help=\"include subdiffusif model\",default=\"1\")\n",
    "\n",
    "parser.add_argument(\"--batch\", help=\"include subdiffusif model\",default=\"0\")\n",
    "\n",
    "#parser.add_argument(\"--format\", help=\"possible format mat or json \",default=\"mat\")\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "ndim = args.ndim\n",
    "filetoopen = args.trackfile\n",
    "res_folder = args.res\n",
    "sub = args.sub\n",
    "batch = args.batch\n",
    "\n",
    "if sub == \"1\":\n",
    "    sub = True\n",
    "else:\n",
    "    sub = False\n",
    "\n",
    "if batch == \"1\":\n",
    "    batch = True\n",
    "else:\n",
    "    batch = False\n",
    "\n",
    "aformat = \"mat\"\n",
    "\n",
    "print \"\"\n",
    "print \"RNN with following parameters:\"\n",
    "if not sub:\n",
    "    print \" - No\",\n",
    "else:\n",
    "    print \" -\",\n",
    "print \"Subdiffusive motion \" ,\n",
    "\n",
    "if not sub:\n",
    "    print \" (to add diffusive motion add the option --sub 1)\"\n",
    "else:\n",
    "    print \" (to remove diffusive motion add the option --sub 0)\"\n",
    "\n",
    "print \" - %i dimensions\"%ndim\n",
    "print \"\"\n",
    "print \"Loading model\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model\n"
     ]
    }
   ],
   "source": [
    "#loading network\n",
    "from scipy.io import loadmat,savemat\n",
    "import numpy as np\n",
    "import theano\n",
    "theano.config.mode=\"FAST_COMPILE\"\n",
    "\n",
    "from Specialist_layer import return_four_paper\n",
    "graph = return_four_paper(ndim=2,inside = 50,permutation=True,inputsize=5)\n",
    "\n",
    "print \"Running model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat,savemat\n",
    "from prePostTools import get_parameters,M1,M0\n",
    "import copy\n",
    "\n",
    "\n",
    "def save_on_mat(name,step_categorie,categories,traj,px,fr,ndim):\n",
    "    \n",
    "    #fich = \"template.mat\"\n",
    "    #Mp = loadmat(fich,squeeze_me=False)\n",
    "    Mp= {'results':{}}\n",
    "    Mp['results'][\"PrM\"] = categories\n",
    "    Mp['results']['track'] = traj.T\n",
    "    Mp['results']['steps'] = np.array(traj[1:,::]-traj[:-1,::]).T\n",
    "    \n",
    "    remove_nan = np.array(copy.deepcopy(step_categorie),dtype=np.float)\n",
    "    \n",
    "    remove_nan[ remove_nan == 9] =  remove_nan[ remove_nan == 9] * np.nan\n",
    "    \n",
    "    Mp['results'][\"ML_states\"] = remove_nan\n",
    "\n",
    "    \n",
    "    res = get_parameters(traj,remove_nan,pixel=px,time=1./fr,ndim=ndim)\n",
    "    mu_emit = []\n",
    "    mu_real = []\n",
    "    sigma_emit = []\n",
    "    D_emit = []\n",
    "    mu_emit = []\n",
    "    for scat in res:\n",
    "        if np.isnan(scat[0]):\n",
    "            continue\n",
    "        \n",
    "        #print \"\\nScat\" ,scat\n",
    "        \n",
    "        mu_real.append(scat[2][0])\n",
    "        if scat[0] in [0,1,2,6,7,8]:\n",
    "            mu_emit.append(np.zeros_like(scat[2][0]))\n",
    "        else:\n",
    "            mu_emit.append(scat[2][0])\n",
    "        sigma_emit.append(scat[2][-1])\n",
    "        D_emit.append(scat[2][-2])\n",
    "\n",
    "    \n",
    "    Mp['results']['ML_params'] = {}\n",
    "    Mp['results']['ML_params'][\"mu_emit\"] = np.array(mu_emit).T\n",
    "    Mp['results']['ML_params'][\"mu_real\"] = np.array(mu_real).T\n",
    "    Mp['results']['ML_params'][\"sigma_emit\"] = np.array(sigma_emit).T\n",
    "    Mp['results']['ML_params'][\"D_emit\"] = np.array(D_emit).T\n",
    "\n",
    "\n",
    "    if name is not None:\n",
    "        savemat(name,Mp)\n",
    "    \n",
    "    return Mp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from prePostTools import clean_initial_trajectory,put_back_nan,clean,traj_to_dist\n",
    "from keras.utils import generic_utils\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def load_weights_old(graph, filepath):\n",
    "    '''Load weights from a HDF5 file.\n",
    "    '''\n",
    "    import h5py\n",
    "    f = h5py.File(filepath, mode='r')\n",
    "    g = f['graph']\n",
    "    weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "    start = 0\n",
    "    \n",
    "    for nl,l in enumerate(graph.layers):\n",
    "        p = l.trainable_weights + l.non_trainable_weights\n",
    "        #print p\n",
    "        if len(p) > 0:\n",
    "            graph.layers[nl].set_weights(weights[start:start+len(p)])\n",
    "        start += len(p)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "ndim = 2\n",
    "filetoopen =\"/home/jarbona/Downloads/v3_crop-1_MinFr30.mat\"\n",
    "res_folder = \"./\"\n",
    "sub = False\n",
    "batch = False\n",
    "aformat = \"mat\"\n",
    "\"\"\"\n",
    "\n",
    "if sub:\n",
    "    print \"Not implemented\" \n",
    "    #graph9.load_weights(\"saved_weights/three_bilayer_sub_bis\")\n",
    "\n",
    "else:\n",
    "    load_weights_old(graph,\"saved_weights/paper_sub_simple=False,diff_sigma=2.0,delta_sigma_directed=6.,ndim=2,anisentropy=0.1,deltav=.4,rho_fixed=False,random_rotation=False_withnoise_0p25_12_18\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def process_one_file(filetoopen,localfolder,filetowrite):\n",
    "    trajs = []\n",
    "    M = loadmat(filetoopen)\n",
    "\n",
    "\n",
    "    pred_RNNs = []\n",
    "    pred_RNN_cats = []\n",
    "\n",
    "    add = { \"tool\": \"RNN\",\n",
    "             \"mu_emit_unit\":\"pixel\",\n",
    "             \"mu_real_unit\":\"pixel\",\n",
    "            \"sigma_emit_unit\":\"pixel\",\n",
    "            \"D_emit_unit\":\"Assuming your unit for the pixel size was nanometer, in mu^2/s\"}\n",
    "    if not M.has_key(\"analysisInfo\"):\n",
    "        M[\"analysisInfo\"] = {}\n",
    "    else:\n",
    "        tmp = {}\n",
    "        for k in M[\"analysisInfo\"].dtype.names:\n",
    "            #print k , len( M[\"analysisInfo\"][k][0][0][0])# ,  M[\"analysisInfo\"][k][0][0] \n",
    "            if len( M[\"analysisInfo\"][k][0][0][0]) == 1:\n",
    "                tmp[k] = M[\"analysisInfo\"][k][0][0][0][0]\n",
    "            else:\n",
    "                tmp[k] =  M[\"analysisInfo\"][k][0][0][0]\n",
    "            #print tmp[k]\n",
    "\n",
    "                   \n",
    "        M[\"analysisInfo\"] = tmp\n",
    "    for k,v in add.items():\n",
    "            M[\"analysisInfo\"][k] = v\n",
    "\n",
    "    if sub:\n",
    "         M[\"analysisInfo\"][\"PrM_labels\"] = np.array(M1,dtype=np.object)\n",
    "    else:\n",
    "         M[\"analysisInfo\"][\"PrM_labels\"] = np.array(M0,dtype=np.object)\n",
    "\n",
    "    px = M[\"analysisInfo\"][\"pixelSize\"]/ 1000. #In micro meter\n",
    "    fr = M[\"analysisInfo\"][\"frameRate\"]\n",
    "\n",
    "\n",
    "\n",
    "    M[\"results\"] = []\n",
    "    #NewField = [\"ML_states\",\"PrM\",\"steps\",'ML_params']\n",
    "\n",
    "    #Copy old fields\n",
    "    #M[\"tracksProc\"] #= {field:M[\"tracksProc\"][field][0] for field in M[\"tracksProc\"].dtype.names}\n",
    "\n",
    "    #print M[\"tracksProc\"][\"pos\"].shape\n",
    "    #Add new fields\n",
    "    #tmp = {}\n",
    "    #for field in NewField:\n",
    "    #    M[\"tracksProc\"][field] = np.empty(len(M[\"tracksProc\"][\"pos\"]), dtype=np.object)\n",
    "\n",
    "    ntraj = len(M[\"tracksProc\"][0][\"pos\"])\n",
    "    progbar = generic_utils.Progbar(ntraj)\n",
    "\n",
    "\n",
    "    for itraj,traj0 in enumerate(M[\"tracksProc\"][0][\"pos\"]):\n",
    "\n",
    "        #print traj\n",
    "        #traj0 = traj\n",
    "\n",
    "        #print traj0.shape\n",
    "        traj,alligned_traj,normed,zeros,nans,added0 = clean_initial_trajectory(traj0)\n",
    "        trajs.append(traj)\n",
    "        #print normed.shape\n",
    "        #pred0 = graph9.predict({\"input1\":normed[newaxis,::,::]})\n",
    "\n",
    "\n",
    "        pred0 = graph.predict({\"input1\":normed[np.newaxis,::,::]},  batch_size=1)\n",
    "\n",
    "        pred_RNN = pred0[\"output\"]\n",
    "        pred_RNN_cat = pred0[\"category\"]\n",
    "\n",
    "        #Inverse these \n",
    "        if not sub:\n",
    "            #print pred_RNN_cat.shape\n",
    "            pred_RNN_cat[0,8:10] = pred_RNN_cat[0,8:10][::-1]\n",
    "            pred_RNN_cat = pred_RNN_cat[0,:len(M0)]\n",
    "\n",
    "\n",
    "        pred_RNN = pred_RNN[0]\n",
    "        pred_RNN_cat = pred_RNN_cat\n",
    "\n",
    "        if added0:\n",
    "            zeros.pop(-1)\n",
    "            traj = traj[:-1,::]\n",
    "            pred_RNN = pred_RNN[:-1]\n",
    "\n",
    "        pred_RNNs.append(pred_RNN)\n",
    "        pred_RNN_cats.append(pred_RNN_cat)\n",
    "\n",
    "\n",
    "\n",
    "        cat =  pred_RNN\n",
    "        fight = False\n",
    "        if not sub:\n",
    "            fight = True\n",
    "        cat = clean(cat,np.argmax(pred_RNN_cat),fight=fight,sub=sub,append_steady=False)\n",
    "\n",
    "        cat = cat.tolist()\n",
    "\n",
    "        cat = put_back_nan(cat,zeros,nans)\n",
    "\n",
    "        assert(len(cat) == len(traj0)-1)\n",
    "\n",
    "\n",
    "        #save_on_mat(res_folder +\"res%i.mat\"%(itraj+1),cat,pred_RNN_cat,traj0)\n",
    "        Mp = save_on_mat(None,cat,pred_RNN_cat,traj0,px=px,fr=fr,ndim=ndim)\n",
    "\n",
    "\n",
    "\n",
    "        M[\"results\"].append( Mp[\"results\"])\n",
    "\n",
    "        progbar.add(1)\n",
    "\n",
    "        #print cat\n",
    "\n",
    "    #M[\"tracksProc\"] = np.array(M[\"tracksProc\"],dtype=)\n",
    "    \n",
    "    final = os.path.join(localfolder,filetowrite)\n",
    "\n",
    "    if aformat == \"mat\":\n",
    "        final += \".mat\"\n",
    "        filetowrite += \".mat\"\n",
    "        savemat(final,M)\n",
    "    else:\n",
    "        final += \".json\"\n",
    "        filetowrite += \".json\"\n",
    "        with open(final,\"w\") as f:\n",
    "            f.write(json.dumps(M))\n",
    "        #print cat\n",
    "        #print cat\n",
    "\n",
    "    print \"Result writen in \",filetowrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing  /home/jarbona/Downloads/v3_crop-1_MinFr30.mat\n",
      "1/1 [==============================] - 0s\n",
      "Result writen in  /home/jarbona/Downloads/v3_crop-1_MinFr30_RNN.mat\n"
     ]
    }
   ],
   "source": [
    "if not batch:\n",
    "    print \"processing \",filetoopen\n",
    "    process_one_file(filetoopen,res_folder , filetoopen[:-4] + \"_RNN\")\n",
    "\n",
    "else:\n",
    "\n",
    "    liste_file = glob.glob(os.path.join(filetoopen,\"\") + \"*.mat\")\n",
    "    liste_file.sort()\n",
    "    \n",
    "    if len(liste_file) == 0:\n",
    "        print \"No file found in \", filetoopen\n",
    "        print \"check the folder specified in -v option\"\n",
    "        raise\n",
    "    if not os.path.exists(os.path.join(filetoopen,\"RNN\")):\n",
    "        print \"The files \" , liste_file \n",
    "        print \"where found, but\" \n",
    "        print \"You have to create a folder called RNN in the directory where your trajectories are stored\"\n",
    "        raise\n",
    "    for filet in liste_file:\n",
    "        \n",
    "        print \"processing \",filet\n",
    "        final_file = os.path.join(\"RNN\",os.path.split(filet)[1])\n",
    "        process_one_file(filet,filetoopen,final_file[:-4]+\"_RNN\")\n",
    "        print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
